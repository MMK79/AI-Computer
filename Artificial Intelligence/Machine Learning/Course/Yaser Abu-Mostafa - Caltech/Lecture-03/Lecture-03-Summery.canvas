{
	"nodes":[
		{"id":"16d8f1e4ff6c7977","type":"text","text":"Lecture-03","x":-400,"y":-110,"width":139,"height":60},
		{"id":"129d96fb71bf330f","type":"text","text":"Now <u>admittedly you lost information in that process</u>. **But the chances are you lost as much as irrelevant information as relevant information.**","x":1728,"y":-945,"width":393,"height":131},
		{"id":"58dfe98a0a1c6eaf","type":"text","text":"Your dealing with a 256 dimension in MNIST Dataset + Bias --> $linear\\ model: (w_{0}, w_{1}, \\dots ,w_{256})$","x":328,"y":-914,"width":740,"height":67},
		{"id":"85447303f9f99ff5","type":"text","text":"Input Representation","x":0,"y":-911,"width":250,"height":60},
		{"id":"0866d80954034562","type":"text","text":"Feature Extraction--> Symmetry + intensity --> $x = (x_{0}, x_{1}, x_{2})$","x":1148,"y":-905,"width":521,"height":50},
		{"id":"4dca86bcd03167fa","type":"text","text":"In classification error is simple: you will get it right or wrong and that is it","x":605,"y":149,"width":250,"height":131},
		{"id":"35425d818ac79c2a","type":"text","text":"The standard Error Function in Linear Regression is Squared Error. $(h(x)- f(x))^2$","x":620,"y":-1,"width":219,"height":118},
		{"id":"0a5fa187fe22c1ee","type":"text","text":"we will use shorthand version, vector or the matrix form","x":649,"y":-360,"width":281,"height":59},
		{"id":"7a45c9004208c9d2","type":"text","text":"$$h(x) = \\sum_{i=0}^{d} w_{i}x_{i} = \\mathbf w^{t}\\mathbf x$$\n","x":688,"y":-260,"width":202,"height":100},
		{"id":"7c84b418ed75be20","type":"file","file":"Artificial Intelligence/Machine Learning/Course/Yaser Abu-Mostafa - Caltech/Lecture-03/Attachments/In-sample-error.md","x":923,"y":-80,"width":400,"height":276},
		{"id":"a554e657349ac6de","type":"text","text":"* if you try to minimize the calculus part you can minimize it with respect to scalar variable, which apply very primitive calculus. ","x":948,"y":-269,"width":350,"height":119},
		{"id":"f19c2bd51faa45f7","type":"text","text":"What is the Problem?\nCredit officers decide on credit lines:\n$(x_1, y_1), \\dots (x_N, y_N)$\n$y_n$ is the credit line for customer $x_n$\nLinear regression tries to replicate that","x":1368,"y":-290,"width":335,"height":161},
		{"id":"32b3f3fb29386384","type":"text","text":"in two-dimension you will get a line, in three-dimension you will get plane, and for more dimension you will get a hyperplane","x":1768,"y":-290,"width":277,"height":160},
		{"id":"fe948d5fe738f3d6","type":"text","text":"One step learning & Building Block ","x":1894,"y":24,"width":190,"height":69},
		{"id":"084ceda429597afd","type":"text","text":"Linear Classification","x":0,"y":-591,"width":250,"height":60},
		{"id":"2afb441f61b790c0","type":"text","text":"Linear Regression","x":0,"y":-240,"width":250,"height":60},
		{"id":"5713bb173ac0d55b","type":"text","text":"Real-value Output + Linear Output","x":327,"y":-240,"width":309,"height":60},
		{"id":"a8e0a4cf82600bc1","type":"text","text":"Define an Error measure --> then algorithm will try to minimize the error measure","x":288,"y":-11,"width":258,"height":139},
		{"id":"56a6df8875b99067","type":"text","text":"How to Measure the Error","x":0,"y":28,"width":250,"height":60},
		{"id":"baef68cc063fc804","type":"text","text":"Linear Regression for Classification","x":0,"y":340,"width":308,"height":62},
		{"id":"44c8ee9caa39a2c3","type":"text","text":"Linear Regression learn a real-value function and classification is a real number too $\\pm 1 \\in \\mathbb R$","x":382,"y":312,"width":289,"height":119},
		{"id":"1be5d18e31257993","type":"text","text":"$\\textcolor{red}{\\mathbf w^{T}x_{n}} \\approx \\textcolor{blue}{y_{n}} = \\pm 1$ ","x":748,"y":342,"width":175,"height":60},
		{"id":"40781b73330ed90c","type":"text","text":"Good Initial weight for Classification","x":427,"y":460,"width":199,"height":60},
		{"id":"1066f2123b500bd2","type":"text","text":"For each example, the value of signal is close to the numerical +1, or -1","x":716,"y":431,"width":240,"height":86},
		{"id":"ac3b96bd784b1e98","type":"text","text":"Problem: want to convert all values to -1 and +1, count the higher number as an error even if it classify them correctly","x":1040,"y":313,"width":285,"height":118},
		{"id":"8543ba9e3e8739a1","type":"text","text":"Difference between linear regression for classification and linear classification","x":1050,"y":474,"width":255,"height":106},
		{"id":"17ff54fb2f69faa1","type":"text","text":"Linear is limited","x":38,"y":580,"width":175,"height":60},
		{"id":"cdd889c0f232caff","type":"text","text":"Where the linearity Come from? It comes from the $w$'s (Weights) not the $x$'s (Data)","x":296,"y":550,"width":270,"height":120},
		{"id":"78550b88e0fd297a","type":"text","text":"Nonlinear Transformation","x":0,"y":760,"width":250,"height":60},
		{"id":"80d1863eb1de533e","type":"text","text":"Transform($\\Phi$) on $x$'s to create $\\mathbf z$ vectors with no computational limit","x":319,"y":740,"width":225,"height":100},
		{"id":"7aabdef70851e2b9","type":"text","text":"* Based on the Domains and Assumption of data --> Good\n* Based on our own Bias --> Bad (Cheating)","x":-18,"y":860,"width":288,"height":156},
		{"id":"1f0f5080d56bbae1","type":"text","text":"Linear Regression - One step learning\n$$h(x) = \\sum_{i=0}^{d} w_{i}x_{i} = \\mathbf w^{t}\\mathbf x$$\nPseudo-matrix\n$\\mathbf w = \\mathbf X^{\\dagger} \\mathbf y$\nLinear Regression for classification\nNon-linear Transformation --> 4 step cycle","x":-457,"y":-11,"width":254,"height":322},
		{"id":"751feff47d7dcdc5","type":"file","file":"Artificial Intelligence/Machine Learning/Course/Yaser Abu-Mostafa - Caltech/Lecture-03/Attachments/PLA-Pocket-algorithm.md","x":298,"y":-716,"width":400,"height":311},
		{"id":"2ec29b0b6dc9f0d4","type":"file","file":"Artificial Intelligence/Machine Learning/Course/Yaser Abu-Mostafa - Caltech/Lecture-03/Attachments/Minimize-in-sample-error.md","x":1400,"y":-86,"width":400,"height":288},
		{"id":"fba599f0693de7a9","type":"file","file":"Artificial Intelligence/Machine Learning/Course/Yaser Abu-Mostafa - Caltech/Lecture-04/Attachments/Nonlinear-transformation.md","x":671,"y":684,"width":634,"height":213}
	],
	"edges":[
		{"id":"d5f56b236c2ad42f","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"85447303f9f99ff5","toSide":"left"},
		{"id":"88964ca4dabaca60","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"084ceda429597afd","toSide":"left"},
		{"id":"1df164cfed529cae","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"2afb441f61b790c0","toSide":"left"},
		{"id":"e2a5fe9a7ebbe144","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"78550b88e0fd297a","toSide":"left"},
		{"id":"0fb1e0946d2d96a9","fromNode":"85447303f9f99ff5","fromSide":"right","toNode":"58dfe98a0a1c6eaf","toSide":"left"},
		{"id":"8b82097948d68661","fromNode":"58dfe98a0a1c6eaf","fromSide":"right","toNode":"0866d80954034562","toSide":"left"},
		{"id":"be950982832f1758","fromNode":"0866d80954034562","fromSide":"right","toNode":"129d96fb71bf330f","toSide":"left"},
		{"id":"8c5adf0e726db0f4","fromNode":"2afb441f61b790c0","fromSide":"right","toNode":"5713bb173ac0d55b","toSide":"left"},
		{"id":"a9b4b21fb8260a62","fromNode":"5713bb173ac0d55b","fromSide":"right","toNode":"7a45c9004208c9d2","toSide":"left"},
		{"id":"e4c361016e51dd40","fromNode":"7a45c9004208c9d2","fromSide":"right","toNode":"a554e657349ac6de","toSide":"left"},
		{"id":"55ed190fdb263405","fromNode":"0a5fa187fe22c1ee","fromSide":"bottom","toNode":"7a45c9004208c9d2","toSide":"top"},
		{"id":"6bddbde59474f883","fromNode":"a554e657349ac6de","fromSide":"right","toNode":"f19c2bd51faa45f7","toSide":"left"},
		{"id":"ad05ef7e3b0f52ab","fromNode":"56a6df8875b99067","fromSide":"right","toNode":"a8e0a4cf82600bc1","toSide":"left"},
		{"id":"63c11cbc2e670d2c","fromNode":"a8e0a4cf82600bc1","fromSide":"right","toNode":"35425d818ac79c2a","toSide":"left"},
		{"id":"5c691498e0f64fd8","fromNode":"4dca86bcd03167fa","fromSide":"top","toNode":"35425d818ac79c2a","toSide":"bottom"},
		{"id":"27c56f0acf0d8ab4","fromNode":"f19c2bd51faa45f7","fromSide":"right","toNode":"32b3f3fb29386384","toSide":"left"},
		{"id":"0c14d2b8c7f95ed1","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"56a6df8875b99067","toSide":"left"},
		{"id":"118a03fc6aeb0c1f","fromNode":"35425d818ac79c2a","fromSide":"right","toNode":"7c84b418ed75be20","toSide":"left"},
		{"id":"7a898698b2e72cec","fromNode":"16d8f1e4ff6c7977","fromSide":"right","toNode":"baef68cc063fc804","toSide":"left"},
		{"id":"9173c7bdec8a090d","fromNode":"baef68cc063fc804","fromSide":"right","toNode":"44c8ee9caa39a2c3","toSide":"left"},
		{"id":"543b810de04d5ffc","fromNode":"44c8ee9caa39a2c3","fromSide":"right","toNode":"1be5d18e31257993","toSide":"left"},
		{"id":"aa2ccd1f96e5002c","fromNode":"1be5d18e31257993","fromSide":"bottom","toNode":"1066f2123b500bd2","toSide":"top"},
		{"id":"3c6b111083a491b6","fromNode":"44c8ee9caa39a2c3","fromSide":"bottom","toNode":"40781b73330ed90c","toSide":"top"},
		{"id":"b5bd9d2462f670fb","fromNode":"1be5d18e31257993","fromSide":"right","toNode":"ac3b96bd784b1e98","toSide":"left"},
		{"id":"abdd101486f07634","fromNode":"8543ba9e3e8739a1","fromSide":"top","toNode":"ac3b96bd784b1e98","toSide":"bottom"},
		{"id":"50ba435615a38d4e","fromNode":"17ff54fb2f69faa1","fromSide":"bottom","toNode":"78550b88e0fd297a","toSide":"top"},
		{"id":"70bd623845f4a00f","fromNode":"78550b88e0fd297a","fromSide":"right","toNode":"80d1863eb1de533e","toSide":"left"},
		{"id":"9866966361f8ffe9","fromNode":"17ff54fb2f69faa1","fromSide":"right","toNode":"cdd889c0f232caff","toSide":"left"},
		{"id":"05885e33486f9be1","fromNode":"cdd889c0f232caff","fromSide":"bottom","toNode":"80d1863eb1de533e","toSide":"top"},
		{"id":"380956152d1a6c8b","fromNode":"80d1863eb1de533e","fromSide":"top","toNode":"cdd889c0f232caff","toSide":"bottom"},
		{"id":"b323fb72ee032a6f","fromNode":"78550b88e0fd297a","fromSide":"bottom","toNode":"7aabdef70851e2b9","toSide":"top"},
		{"id":"1bec004e25c3d013","fromNode":"16d8f1e4ff6c7977","fromSide":"bottom","toNode":"1f0f5080d56bbae1","toSide":"top"},
		{"id":"139dd6e7df8157ed","fromNode":"084ceda429597afd","fromSide":"right","toNode":"751feff47d7dcdc5","toSide":"left"},
		{"id":"4c187c281f354a0c","fromNode":"7c84b418ed75be20","fromSide":"right","toNode":"2ec29b0b6dc9f0d4","toSide":"left"},
		{"id":"523a2d949fb0d331","fromNode":"2ec29b0b6dc9f0d4","fromSide":"right","toNode":"fe948d5fe738f3d6","toSide":"left"},
		{"id":"f85ad2212ce49735","fromNode":"80d1863eb1de533e","fromSide":"right","toNode":"fba599f0693de7a9","toSide":"left"}
	]
}