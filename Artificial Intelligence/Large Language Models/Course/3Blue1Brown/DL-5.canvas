{
	"nodes":[
		{"id":"46d6199779e162e0","type":"group","x":3120,"y":-126,"width":4520,"height":1412,"label":"Train a Transformer Model"},
		{"id":"3e1b6ef3f7186bba","x":9600,"y":4400,"width":4760,"height":600,"type":"group","label":"Soft Max"},
		{"id":"e18c4723472c0383","type":"group","x":8560,"y":3120,"width":2201,"height":742,"label":"Embedding Matrix"},
		{"id":"e608d62269153203","type":"group","x":4335,"y":208,"width":1405,"height":1058,"label":"Transformare Operations"},
		{"id":"c32d539eb3fd8d6b","type":"group","x":5876,"y":685,"width":1739,"height":447,"label":"Last Touch on Model"},
		{"id":"be6bff1c248ca439","type":"group","x":3780,"y":1371,"width":1459,"height":476,"label":"ML"},
		{"id":"3b782998fd9ddaa6","type":"group","x":4355,"y":272,"width":1365,"height":440,"label":"Attention Block"},
		{"id":"afc8c560585f8c69","type":"group","x":9697,"y":4060,"width":1830,"height":231,"label":"Un-Embedding Matrix"},
		{"id":"09f5694c5de6d427","type":"group","x":10794,"y":3531,"width":1465,"height":281,"label":"Context Size"},
		{"id":"d1c51993e0540cc8","type":"group","x":1900,"y":320,"width":700,"height":520,"label":"GPT-2"},
		{"id":"8b6052147fd1d0f1","type":"group","x":4355,"y":912,"width":831,"height":334,"label":"FFNN"},
		{"id":"165bb859b57e8933","type":"group","x":8340,"y":460,"width":744,"height":270,"label":"Input + Setting for Model"},
		{"id":"5b7dc65f22ebfc21","type":"group","x":4269,"y":2111,"width":364,"height":420,"label":"DL"},
		{"id":"ae5f95667fcd7c8f","type":"text","text":"Generative","x":-337,"y":-193,"width":130,"height":60},
		{"id":"96ca2698b82260a3","type":"text","text":"Pre","x":-207,"y":-193,"width":76,"height":60},
		{"id":"2e3b97bf09a56eaa","type":"text","text":"GPT","x":-580,"y":-193,"width":83,"height":60},
		{"id":"850af36e6f499dab","type":"text","text":"Trained","x":-131,"y":-193,"width":106,"height":60},
		{"id":"24c0f6c8544e4e99","type":"text","text":"Transformer","x":-25,"y":-193,"width":140,"height":60},
		{"id":"cd1c472f35bc6c68","type":"text","text":"Bot generate text","x":-538,"y":-369,"width":177,"height":60},
		{"id":"21b1752648c234f1","type":"text","text":"More room to Fine-Tune it for specific task with additional training","x":-337,"y":-367,"width":530,"height":58},
		{"id":"29a8c304aa2b92a0","type":"text","text":"Model went through process of learning massive amount of data","x":-565,"y":40,"width":517,"height":50},
		{"id":"f3fa96f88a34389e","type":"text","text":"Specific Neural Network Machine Learning Model Core Invention","x":45,"y":40,"width":517,"height":50},
		{"id":"ac2ec5e08805bf47","type":"text","text":"You can build different models with use of transformers:\nVoice-to-Text\nText-to-Voice\nText-to-Image $\\rightarrow$ DALL-E, MidJourney\nBase Transformer (Attention is All You Need Paper) $\\rightarrow$ Translation (Machine Translation)","x":640,"y":-17,"width":685,"height":163},
		{"id":"d66fa14068ec9e44","type":"text","text":"Input = Text + Other Medias $\\xrightarrow{Produce}$ Next Word","x":1460,"y":35,"width":389,"height":60},
		{"id":"109e9b54e827bb4c","type":"text","text":" A Probability distribution over all possible tokens that might come next","x":7035,"y":1056,"width":560,"height":52},
		{"id":"ad55606f413e9fe8","type":"text","text":"You have your system, now we want to develop a chatbot","x":7758,"y":556,"width":494,"height":50},
		{"id":"5b29bb5c89f5d0ec","type":"text","text":"User initial Question/Prompt as first bit of dialogue","x":8504,"y":660,"width":416,"height":50},
		{"id":"f2349ab15ee41cce","type":"text","text":"System Prompt: A little bit of text which establish setting of a user interacting with chatbot","x":8360,"y":480,"width":704,"height":50},
		{"id":"f985168fe386acb9","type":"text","text":"Now system start prediction","x":9181,"y":570,"width":255,"height":52},
		{"id":"0e0f3a0d5f4c4e13","type":"text","text":"Perform certain operation on it ","x":6586,"y":1052,"width":273,"height":60},
		{"id":"ea2564516960edea","type":"text","text":"Last Vector","x":6655,"y":950,"width":134,"height":50},
		{"id":"9be3e6f869176a74","type":"text","text":"How to read underline of these matrices","x":6395,"y":708,"width":341,"height":62},
		{"id":"187b0860dffa523e","type":"text","text":"Hope is essential meaning of the passage influenced","x":6223,"y":950,"width":432,"height":50},
		{"id":"f531e90f1db794d5","type":"text","text":"Giant pile of matrix multiplication","x":5896,"y":705,"width":289,"height":65},
		{"id":"2d2ebb86bc155204","type":"text","text":"Repeat ","x":5989,"y":830,"width":103,"height":60},
		{"id":"4cbb4bbfff3d5ab1","type":"text","text":"Responsible to figure which word in the context is relevant to update the meaning of which other word","x":5242,"y":292,"width":425,"height":68},
		{"id":"209f29d5f96d0890","type":"text","text":"Should be updated","x":5511,"y":480,"width":189,"height":60},
		{"id":"3778c151a4adbc47","type":"text","text":"Meaning","x":5397,"y":480,"width":114,"height":60},
		{"id":"e1cc67ab978f8032","type":"text","text":"How","x":5313,"y":480,"width":84,"height":60},
		{"id":"192f27b7a408bdcf","type":"text","text":"Asking a long list of question about each vector and then update them base on the answer","x":4771,"y":1157,"width":395,"height":69},
		{"id":"e592ecead682a1fa","type":"text","text":"They go through some operation in Parallel","x":4787,"y":1043,"width":362,"height":50},
		{"id":"262ff0b978373c38","type":"text","text":"No talking between Vectors","x":4843,"y":932,"width":251,"height":60},
		{"id":"344138941c4359b8","type":"text","text":"Allows vectors to talk to each other and pass information back and forth $\\xrightarrow{so}$ they can update their values","x":4647,"y":410,"width":462,"height":70},
		{"id":"77062cbbf3145407","type":"text","text":"Entries of Vectors","x":4860,"y":632,"width":180,"height":50},
		{"id":"3af00067d8218e9e","type":"text","text":"Operation","x":4922,"y":792,"width":124,"height":50},
		{"id":"4c5b5e1f015a4485","type":"text","text":"Similar Meaning = Closer to Each Other","x":4595,"y":-42,"width":336,"height":50},
		{"id":"f8e08ed9c9443c00","type":"text","text":"Vector pass through different kind of ","x":4604,"y":792,"width":318,"height":50},
		{"id":"bd3f12709ef16927","type":"text","text":"Multi Layer Perceptron (MLP)\nOr\nFeed Forward neural Network","x":4375,"y":992,"width":265,"height":86},
		{"id":"899bd374a02729c3","type":"text","text":"Attention Block","x":4375,"y":415,"width":162,"height":60},
		{"id":"acc3de769d642998","type":"text","text":"Think of them as a Coordinates in very High dimensional space (in GPT-3, 12,288)","x":4135,"y":-48,"width":361,"height":62},
		{"id":"b325dd21ca09f432","type":"text","text":"Encode meaning of that Piece/Token","x":4191,"y":52,"width":316,"height":60},
		{"id":"89ec35ceadb9136e","type":"text","text":"Operations","x":4152,"y":219,"width":132,"height":50},
		{"id":"fb33817cb8c308d2","type":"text","text":"Sequence of vector pass through","x":3859,"y":219,"width":293,"height":50},
		{"id":"2f610ea4ff910c78","type":"text","text":"Vector","x":3956,"y":52,"width":99,"height":60},
		{"id":"b496ff91ec6c2797","type":"text","text":"Each token associated with a","x":3695,"y":52,"width":261,"height":60},
		{"id":"bf7063f1d69a948d","type":"text","text":"List of Numbers","x":3922,"y":-106,"width":167,"height":60},
		{"id":"246ab3c558286e1d","type":"text","text":"Called Tokens:\nwords, pieces of words, character combination, patches of image, chunks of sound","x":3390,"y":14,"width":223,"height":137},
		{"id":"1945768a9e388910","type":"text","text":"Pieces","x":3451,"y":-106,"width":100,"height":60},
		{"id":"845caa3d00f8ace0","type":"text","text":"1. Input breaks in to bunch of little","x":3140,"y":-106,"width":311,"height":60},
		{"id":"f1b502d28fad2723","type":"text","text":"Still happening in new models","x":2695,"y":550,"width":277,"height":60},
		{"id":"018a6206fd347c0e","type":"text","text":"Take a random sample from distribution that it just generated","x":1977,"y":480,"width":493,"height":63},
		{"id":"3543c017a3b1e69e","type":"text","text":"Tasks that require intuition and pattern recognition","x":4802,"y":1391,"width":417,"height":50},
		{"id":"d8d63ce46a06a3ce","type":"text","text":"Machine Learning","x":3800,"y":1506,"width":250,"height":60},
		{"id":"f93d8ad716889628","type":"text","text":"Any model where you using data to determine how a model","x":4182,"y":1506,"width":479,"height":60},
		{"id":"f6c8b5d0dce02302","type":"text","text":"behave","x":4661,"y":1506,"width":104,"height":60},
		{"id":"e33a5dc09829c7dc","type":"text","text":"Rather than explicitly define procedures by writing code\n<center>Instead</center>\n\nsetup a flexible structure with tunable parameter $\\rightarrow$ now give it sample of input and what output of that input should look like, so model will tune these parameters to mimic this behavior","x":4182,"y":1631,"width":537,"height":196},
		{"id":"1c7197db7bab0de2","type":"text","text":"It is not a given that you can create some giant model with huge number of parameters without it overfite on data or being completely intractable to train","x":4232,"y":1951,"width":438,"height":110},
		{"id":"3e6b929358be01f4","type":"text","text":"Deep-Learning:\nIntroduce models that have proven to scale remarkably well","x":4289,"y":2131,"width":324,"height":99},
		{"id":"f2026cfb9e4c373b","type":"text","text":"All of them use same Training Algorithm","x":4326,"y":2311,"width":250,"height":54},
		{"id":"022c8854f6a22cdd","type":"text","text":"Back-Propagation","x":4360,"y":2451,"width":182,"height":60},
		{"id":"08a41ea55b4d7c45","type":"text","text":"Models need to follow specific format","x":4765,"y":2454,"width":323,"height":55},
		{"id":"632582c87e58faba","type":"text","text":"Matrix","x":5088,"y":2454,"width":97,"height":55},
		{"id":"db4e3ebfd5f5e0fc","type":"text","text":"Array of real number","x":5222,"y":2571,"width":200,"height":60},
		{"id":"809dfb68db0264aa","type":"text","text":"Tensor = Higher Dimensional Arrays","x":5502,"y":2571,"width":311,"height":60},
		{"id":"5a1fd6a2283d0423","type":"text","text":"Now this input data will progressively transform into many distinct layers ","x":5813,"y":2691,"width":574,"height":59},
		{"id":"a977230c14d89b55","type":"text","text":"Until Final Layer = Output","x":6202,"y":2811,"width":250,"height":60},
		{"id":"2f49512b4e57cc22","type":"text","text":"Only way for these parameters to interact with data is $\\rightarrow$ Weighted Sum + Nonlinear Functions (Which not depend on parameters)","x":6882,"y":2884,"width":420,"height":105},
		{"id":"258aa03240021aa8","type":"text","text":"We don't see weighted sums explicitly","x":7382,"y":2909,"width":328,"height":55},
		{"id":"288bbe4e2b34077d","type":"text","text":"Model parameter in deep learning = Weight","x":6202,"y":2911,"width":440,"height":50},
		{"id":"21fd3aba8f4e9124","type":"text","text":"Packaged together as a various component in a matrix ($\\mathbf W$) vector ($\\mathbf x$) product\n$$\\mathbf W . \\mathbf x$$\n$\\mathbf W$ (Weights): Brain of the model, get trained, determine how model behave\n$\\mathbf x$ (Data): Encode input feed into models","x":7842,"y":2867,"width":624,"height":140},
		{"id":"6ba7d97e4b1b609a","type":"text","text":"GPT-3\n175 Billion Weights\n28 Thousand","x":8222,"y":3080,"width":187,"height":86},
		{"id":"54c6a049128212f3","type":"text","text":"Matrices","x":8352,"y":3138,"width":114,"height":28},
		{"id":"0554543036236b0c","type":"text","text":"Fall into 8 Different Category","x":8279,"y":3220,"width":260,"height":60},
		{"id":"fd78c810d173da69","type":"text","text":"GPT-3 12,288 Dimension ","x":9390,"y":3497,"width":250,"height":60},
		{"id":"bab9c5c5257cb2ae","type":"text","text":"Direction in Space have a Semantic meaning\n<center>Low Distance = Closer Meaning</center>\n<center>Directions = Encode Meaning</center>\n<center>Dot product of two vector =  way to measure how well they align</center>","x":9610,"y":3602,"width":511,"height":136},
		{"id":"ce687c0218fbf7e7","type":"text","text":"Multiply Correspond Component then adding the result\n50,000 Tokens x 12,000 dimensions = 600,000,000 weights (just a small part of 175 Billion weights)","x":9970,"y":3782,"width":771,"height":60},
		{"id":"b303565c8353b32a","type":"text","text":"Common Approach = Word Embedding","x":8967,"y":3502,"width":335,"height":50},
		{"id":"c2b0324a86564b64","type":"text","text":"What vector each word turn into in first step","x":9270,"y":3342,"width":370,"height":55},
		{"id":"95212603c850697e","type":"text","text":"Random value at start, will be learn base on data","x":9270,"y":3422,"width":402,"height":50},
		{"id":"6dddc966145896f7","type":"text","text":"Model have predefined vocabulary = Some list of possible words ","x":8580,"y":3140,"width":518,"height":50},
		{"id":"d99c16be0178bf71","type":"text","text":"1. Embedding Matrix ($\\mathbf W_E$)","x":8710,"y":3222,"width":257,"height":60},
		{"id":"21773d55df7ccc99","type":"text","text":"Single Column for each of these words","x":9010,"y":3227,"width":331,"height":50},
		{"id":"bb3acbefb5138d9e","type":"text","text":"Context Size:\nNetwork only can process fix number of vectors; GPT context size = 2,048","x":10814,"y":3551,"width":590,"height":64},
		{"id":"82689f1bf8452e46","type":"text","text":"Limit how much text it can incorporate when it is making prediction of next word ","x":11609,"y":3555,"width":630,"height":60},
		{"id":"c4edcea482c21ffd","type":"text","text":"Lost in the middle dilemma\nSay random things as it goes by","x":11775,"y":3712,"width":299,"height":80},
		{"id":"a81ac51fa5ea750c","type":"text","text":"Append that","x":2101,"y":760,"width":250,"height":60},
		{"id":"fda2144253d14b34","type":"text","text":"You have a prediction model","x":2095,"y":180,"width":256,"height":60},
		{"id":"915f52bd8ff6954a","type":"text","text":"Give it an initial Snippet to work with","x":2061,"y":340,"width":324,"height":62},
		{"id":"0b2b2797046a2673","type":"text","text":"$\\times$","x":9658,"y":4190,"width":59,"height":60},
		{"id":"334846dd2fb9f31a","type":"text","text":"Vector of All Tokens in Vocabulary","x":9717,"y":4191,"width":298,"height":60},
		{"id":"2a5e29759b20c690","type":"text","text":")","x":10015,"y":4191,"width":50,"height":60},
		{"id":"2596fd089bcf8311","type":"text","text":"$\\times$","x":9658,"y":4251,"width":59,"height":60},
		{"id":"2c50295c0321bcea","type":"text","text":"End of Transformer\nDesire output = Probability Distribution over all tokens that might come next","x":8589,"y":4180,"width":611,"height":80},
		{"id":"5f13b1ee5a93a3fb","type":"text","text":"1. (","x":9410,"y":4189,"width":78,"height":62},
		{"id":"c2dbd2b46a277158","type":"text","text":"Map Last Vector","x":9488,"y":4189,"width":170,"height":62},
		{"id":"c131cf6c3d854499","type":"text","text":"","x":7300,"y":4180,"width":1,"height":80},
		{"id":"53044a1aabfc1cad","type":"text","text":"","x":8680,"y":4077,"width":1,"height":60},
		{"id":"51132313db89b266","type":"text","text":"Initialize randomly but will be learned during learning process","x":10140,"y":4084,"width":494,"height":50},
		{"id":"8b77a5f9e1d7f993","type":"text","text":"One row for each word in Vocabulary each row have same element of embedding (50,000 word in GPT)\n<center>Dimension = Column = Embedding dimension</center>","x":10140,"y":4171,"width":797,"height":100},
		{"id":"940bfde65ea878bc","type":"text","text":"50,000 (word) $\\times$ 12,000 (dimension) = 600,000,000 weights","x":11000,"y":4196,"width":489,"height":50},
		{"id":"db5ca06ba52cae40","type":"text","text":"Is Prediction next word different than Generating Text?","x":2000,"y":35,"width":446,"height":60},
		{"id":"68663e6cc7fc1595","x":10516,"y":4542,"width":474,"height":113,"type":"text","text":"Turn Arbitrary number into Probability Distribution, Means;\n<center>Higher Value = Closer to 1</center>\n<center>Lower  Value = Closer to 0</center>"},
		{"id":"0861e61a83d98cc3","x":11235,"y":4574,"width":732,"height":50,"type":"text","text":"But in Deep Learning after matrices multiplication values are negative and won't add up to one"},
		{"id":"f8b35a7d2c8e3c79","x":11476,"y":4795,"width":250,"height":60,"type":"text","text":"Soft Max"},
		{"id":"972c07fb3d09aedd","x":11770,"y":4685,"width":333,"height":280,"type":"text","text":"1. Raise $e$ to power of each number\n2. Take sum of all positive values = \n   $$\\sum_{n=0}^ {N-1}e^{x_n}$$\n3. Divide each term by that sum = \n   $$\\frac{x_1}{\\sum_{n=0}^ {N-1}e^{x_n}}$$"},
		{"id":"9170ba380be1996d","x":12190,"y":4763,"width":660,"height":124,"type":"text","text":"If one number is significantly bigger $\\xrightarrow{cause}$ Corresponding term dominate distribution $\\xrightarrow{but}$ it is softer than just picking the max $\\xrightarrow{mean}$ If other values are similarly large they also get meaningful distribution and every thing changes continuously as you continuously vary inputs"},
		{"id":"892c5a26a2062433","x":13070,"y":4705,"width":756,"height":240,"type":"text","text":"Constant T (Temperature)\n* Denominator of exponent \n  $$e^{\\frac{x_1}{T}}$$\n* Higher T = more meaning to lower values = more uniform distribution\n* Lower T = more meaning to bigger value\n* T = 0 $\\rightarrow$ all the weight go to that maximum value $\\rightarrow$ always go with the most predictable word"},
		{"id":"372204348461db3b","type":"text","text":"Soft Max","x":9620,"y":4436,"width":116,"height":60},
		{"id":"068a13e34f0f4e71","x":9838,"y":4436,"width":508,"height":60,"type":"text","text":"Function that Normalize this Vector into Probability Distribution"},
		{"id":"c6da0baf5ee2e7df","x":10451,"y":4441,"width":539,"height":50,"type":"text","text":"If you want sequence of numbers act as a Probability Distribution"},
		{"id":"a43d61cea31a2658","x":11110,"y":4420,"width":305,"height":93,"type":"text","text":"1. Each value be between 0 and 1\n   <center>+</center>\n2. Sum of Values equal to 1"},
		{"id":"c615d72d9e188331","type":"text","text":"There are other tokens too with their own context rich meaning","x":8943,"y":4700,"width":506,"height":50},
		{"id":"6874e44b17f68800","type":"text","text":"Training Process","x":8680,"y":4700,"width":172,"height":50},
		{"id":"76d11cda2cf9378d","type":"text","text":"It is much more efficient, to use these vectors in the find layer to simultaneously make prediction of what comes immediately after it","x":8207,"y":4675,"width":382,"height":100},
		{"id":"2118b76aceaa9883","x":13920,"y":4765,"width":402,"height":120,"type":"text","text":"T api won't let you pick bigger than 2\n* No mathematical reason $\\rightarrow$ hyper parameter"},
		{"id":"532225b24fc30400","type":"text","text":"2. Un-embedding Matrix ($\\mathbf W_u$)","x":9709,"y":4084,"width":315,"height":53},
		{"id":"5c6e4cc625757bb4","x":13895,"y":4540,"width":453,"height":91,"type":"text","text":"Out-put of Soft-Max = Probabilities\nInput of Soft-max = Logits (raw Un-normalize output)\n$\\mathbf W_u$ (Un-embedding matrix) $\\times$ Last vector map"}
	],
	"edges":[
		{"id":"8061b1dd11de515b","fromNode":"2e3b97bf09a56eaa","fromSide":"right","toNode":"ae5f95667fcd7c8f","toSide":"left","label":"Stands for"},
		{"id":"5bea06fefc71c755","fromNode":"ae5f95667fcd7c8f","fromSide":"top","toNode":"cd1c472f35bc6c68","toSide":"bottom"},
		{"id":"50577dd47327d141","fromNode":"850af36e6f499dab","fromSide":"bottom","toNode":"29a8c304aa2b92a0","toSide":"top"},
		{"id":"ba8623c231931a7d","fromNode":"96ca2698b82260a3","fromSide":"top","toNode":"21b1752648c234f1","toSide":"bottom"},
		{"id":"e766973b63cc77f9","fromNode":"24c0f6c8544e4e99","fromSide":"bottom","toNode":"f3fa96f88a34389e","toSide":"top"},
		{"id":"1639524fe873a8df","fromNode":"f3fa96f88a34389e","fromSide":"right","toNode":"ac2ec5e08805bf47","toSide":"left"},
		{"id":"7e0d2bf5a9a23a60","fromNode":"ac2ec5e08805bf47","fromSide":"right","toNode":"d66fa14068ec9e44","toSide":"left","label":"Focus"},
		{"id":"c8998a1859101110","fromNode":"d66fa14068ec9e44","fromSide":"right","toNode":"db5ca06ba52cae40","toSide":"left","label":"Question"},
		{"id":"fe1546f02cc08748","fromNode":"db5ca06ba52cae40","fromSide":"bottom","toNode":"fda2144253d14b34","toSide":"top","label":"Imagine"},
		{"id":"e1b0da2a7742d786","fromNode":"fda2144253d14b34","fromSide":"bottom","toNode":"915f52bd8ff6954a","toSide":"top","label":"Simple way to make it Generate"},
		{"id":"1a94d4efad7bd139","fromNode":"915f52bd8ff6954a","fromSide":"bottom","toNode":"018a6206fd347c0e","toSide":"top","label":"Then"},
		{"id":"74f4f4510eb48532","fromNode":"018a6206fd347c0e","fromSide":"bottom","toNode":"a81ac51fa5ea750c","toSide":"top","label":"Now"},
		{"id":"ff420421622ef61f","fromNode":"a81ac51fa5ea750c","fromSide":"right","toNode":"915f52bd8ff6954a","toSide":"right","label":"Repeat the Process"},
		{"id":"f463896511c0f4c9","fromNode":"d1c51993e0540cc8","fromSide":"right","toNode":"f1b502d28fad2723","toSide":"left"},
		{"id":"aaf536577aba2110","fromNode":"1945768a9e388910","fromSide":"bottom","toNode":"246ab3c558286e1d","toSide":"top"},
		{"id":"c9573f05b35466be","fromNode":"246ab3c558286e1d","fromSide":"right","toNode":"b496ff91ec6c2797","toSide":"left"},
		{"id":"a0d98d8bbf6d7328","fromNode":"2f610ea4ff910c78","fromSide":"top","toNode":"bf7063f1d69a948d","toSide":"bottom"},
		{"id":"4dab14fb138a546c","fromNode":"2f610ea4ff910c78","fromSide":"top","toNode":"acc3de769d642998","toSide":"left"},
		{"id":"26967f315062b40d","fromNode":"acc3de769d642998","fromSide":"right","toNode":"4c5b5e1f015a4485","toSide":"left"},
		{"id":"376622befa522aff","fromNode":"2f610ea4ff910c78","fromSide":"right","toNode":"b325dd21ca09f432","toSide":"left","label":"Purpose"},
		{"id":"79116bbfc5191526","fromNode":"b325dd21ca09f432","fromSide":"right","toNode":"4c5b5e1f015a4485","toSide":"left","label":"Which"},
		{"id":"0c4c06b3e3634ec5","fromNode":"2f610ea4ff910c78","fromSide":"bottom","toNode":"fb33817cb8c308d2","toSide":"top"},
		{"id":"d09d187e0f323fbf","fromNode":"899bd374a02729c3","fromSide":"right","toNode":"344138941c4359b8","toSide":"left"},
		{"id":"99e84a78a78443bf","fromNode":"344138941c4359b8","fromSide":"right","toNode":"4cbb4bbfff3d5ab1","toSide":"left"},
		{"id":"c52466c38d09fbd5","fromNode":"344138941c4359b8","fromSide":"right","toNode":"e1cc67ab978f8032","toSide":"left"},
		{"id":"e7fb00702b14131a","fromNode":"3778c151a4adbc47","fromSide":"top","toNode":"4cbb4bbfff3d5ab1","toSide":"bottom","toEnd":"none","label":"+"},
		{"id":"0d43bd09119de660","fromNode":"3af00067d8218e9e","fromSide":"bottom","toNode":"bd3f12709ef16927","toSide":"top"},
		{"id":"0752c0129981cb26","fromNode":"77062cbbf3145407","fromSide":"bottom","toNode":"f8e08ed9c9443c00","toSide":"top"},
		{"id":"00a5b82ea575dd47","fromNode":"262ff0b978373c38","fromSide":"bottom","toNode":"e592ecead682a1fa","toSide":"top","toEnd":"none","label":"+"},
		{"id":"b91d080ae8fabd4c","fromNode":"bd3f12709ef16927","fromSide":"right","toNode":"262ff0b978373c38","toSide":"left"},
		{"id":"3d2413a96c8c8fec","fromNode":"bd3f12709ef16927","fromSide":"right","toNode":"e592ecead682a1fa","toSide":"left"},
		{"id":"d8092218f4573cb7","fromNode":"e592ecead682a1fa","fromSide":"bottom","toNode":"192f27b7a408bdcf","toSide":"top"},
		{"id":"e0078c00a4b99013","fromNode":"89ec35ceadb9136e","fromSide":"bottom","toNode":"8b6052147fd1d0f1","toSide":"left"},
		{"id":"c1170f5a9c471f53","fromNode":"89ec35ceadb9136e","fromSide":"bottom","toNode":"3b782998fd9ddaa6","toSide":"left"},
		{"id":"e8a7fe717ff35945","fromNode":"3778c151a4adbc47","fromSide":"bottom","toNode":"77062cbbf3145407","toSide":"right"},
		{"id":"176b66566872815f","fromNode":"e608d62269153203","fromSide":"right","toNode":"f531e90f1db794d5","toSide":"left"},
		{"id":"7826ecc60e64e855","fromNode":"f531e90f1db794d5","fromSide":"right","toNode":"9be3e6f869176a74","toSide":"left","label":"Main Thing"},
		{"id":"00a186e56779fe56","fromNode":"f531e90f1db794d5","fromSide":"bottom","toNode":"2d2ebb86bc155204","toSide":"top","toEnd":"none","label":"+"},
		{"id":"f7f621ecb6982c7e","fromNode":"2d2ebb86bc155204","fromSide":"bottom","toNode":"187b0860dffa523e","toSide":"left","label":"Why we repeat?"},
		{"id":"19578ba9fb453d20","fromNode":"ea2564516960edea","fromSide":"bottom","toNode":"0e0f3a0d5f4c4e13","toSide":"top"},
		{"id":"aac404ec29fb534b","fromNode":"0e0f3a0d5f4c4e13","fromSide":"right","toNode":"109e9b54e827bb4c","toSide":"left","label":"Produce"},
		{"id":"5b88083a9914ed0e","fromNode":"f1b502d28fad2723","fromSide":"right","toNode":"46d6199779e162e0","toSide":"left"},
		{"id":"da8f4a02bb8a0b61","fromNode":"f1b502d28fad2723","fromSide":"right","toNode":"845caa3d00f8ace0","toSide":"left","label":"Start"},
		{"id":"9249a732d787f5dc","fromNode":"46d6199779e162e0","fromSide":"right","toNode":"ad55606f413e9fe8","toSide":"left"},
		{"id":"7c2ec71890a6e415","fromNode":"ad55606f413e9fe8","fromSide":"right","toNode":"f2349ab15ee41cce","toSide":"left"},
		{"id":"ee5ad03f78fccfaf","fromNode":"ad55606f413e9fe8","fromSide":"right","toNode":"5b29bb5c89f5d0ec","toSide":"left"},
		{"id":"2031f04a2d19f599","fromNode":"f2349ab15ee41cce","fromSide":"bottom","toNode":"5b29bb5c89f5d0ec","toSide":"top","toEnd":"none","label":"+"},
		{"id":"91846cefbf64f3ed","fromNode":"165bb859b57e8933","fromSide":"right","toNode":"f985168fe386acb9","toSide":"left"},
		{"id":"6088229937f02cc2","fromNode":"d8d63ce46a06a3ce","fromSide":"right","toNode":"f93d8ad716889628","toSide":"left"},
		{"id":"7bfd154beda255bf","fromNode":"d8d63ce46a06a3ce","fromSide":"right","toNode":"e33a5dc09829c7dc","toSide":"left"},
		{"id":"ec7064843b723eeb","fromNode":"f6c8b5d0dce02302","fromSide":"top","toNode":"3543c017a3b1e69e","toSide":"left"},
		{"id":"0e328950a217f49c","fromNode":"e33a5dc09829c7dc","fromSide":"bottom","toNode":"1c7197db7bab0de2","toSide":"top","label":"Problem"},
		{"id":"7bd41647fc7d6be3","fromNode":"1c7197db7bab0de2","fromSide":"bottom","toNode":"3e6b929358be01f4","toSide":"top","label":"Solution"},
		{"id":"b098eb5936e66bdd","fromNode":"3e6b929358be01f4","fromSide":"bottom","toNode":"f2026cfb9e4c373b","toSide":"top","label":"Why? How?"},
		{"id":"1fd3ba3d1b7a8baf","fromNode":"f2026cfb9e4c373b","fromSide":"bottom","toNode":"022c8854f6a22cdd","toSide":"top","label":"Called"},
		{"id":"b1568ae64471f015","fromNode":"022c8854f6a22cdd","fromSide":"right","toNode":"08a41ea55b4d7c45","toSide":"left","label":"Basic Rule\nTo make it Work"},
		{"id":"6adaa2b7f506aeb5","fromNode":"632582c87e58faba","fromSide":"bottom","toNode":"db4e3ebfd5f5e0fc","toSide":"left"},
		{"id":"670e24f59962a634","fromNode":"db4e3ebfd5f5e0fc","fromSide":"right","toNode":"809dfb68db0264aa","toSide":"left"},
		{"id":"102d19697e695565","fromNode":"809dfb68db0264aa","fromSide":"bottom","toNode":"5a1fd6a2283d0423","toSide":"left"},
		{"id":"27dba406da0b80db","fromNode":"5a1fd6a2283d0423","fromSide":"bottom","toNode":"a977230c14d89b55","toSide":"left"},
		{"id":"994a064b2eb9fc04","fromNode":"5a1fd6a2283d0423","fromSide":"bottom","toNode":"288bbe4e2b34077d","toSide":"left"},
		{"id":"3f33112f1d3b6fc2","fromNode":"288bbe4e2b34077d","fromSide":"right","toNode":"2f49512b4e57cc22","toSide":"left","label":"Key Features of\nThese Models"},
		{"id":"0781e5213513991f","fromNode":"2f49512b4e57cc22","fromSide":"right","toNode":"258aa03240021aa8","toSide":"left"},
		{"id":"a529277f7f7f4c09","fromNode":"258aa03240021aa8","fromSide":"right","toNode":"21fd3aba8f4e9124","toSide":"left","label":"Instead"},
		{"id":"af301e6ef9b299fc","fromNode":"bd3f12709ef16927","fromSide":"bottom","toNode":"be6bff1c248ca439","toSide":"top"},
		{"id":"9e4a24224a5ade81","fromNode":"21fd3aba8f4e9124","fromSide":"bottom","toNode":"6ba7d97e4b1b609a","toSide":"left"},
		{"id":"17acca7b7c52f6f7","fromNode":"54c6a049128212f3","fromSide":"bottom","toNode":"0554543036236b0c","toSide":"top"},
		{"id":"f66c123e29aa00ea","fromNode":"0554543036236b0c","fromSide":"right","toNode":"d99c16be0178bf71","toSide":"left"},
		{"id":"08a14265d13753ea","fromNode":"d99c16be0178bf71","fromSide":"right","toNode":"21773d55df7ccc99","toSide":"left"},
		{"id":"d8d122ec1097b8ff","fromNode":"6dddc966145896f7","fromSide":"bottom","toNode":"d99c16be0178bf71","toSide":"top"},
		{"id":"79a34c748a052997","fromNode":"21773d55df7ccc99","fromSide":"bottom","toNode":"c2b0324a86564b64","toSide":"left"},
		{"id":"3f36a7650d883271","fromNode":"21773d55df7ccc99","fromSide":"bottom","toNode":"95212603c850697e","toSide":"left"},
		{"id":"7631bb57fc0f4873","fromNode":"d99c16be0178bf71","fromSide":"bottom","toNode":"b303565c8353b32a","toSide":"left"},
		{"id":"b669e8e9d7164fb9","fromNode":"b303565c8353b32a","fromSide":"right","toNode":"fd78c810d173da69","toSide":"left"},
		{"id":"5b41d39624e0cc2a","fromNode":"fd78c810d173da69","fromSide":"bottom","toNode":"bab9c5c5257cb2ae","toSide":"left"},
		{"id":"2043ce913b96b620","fromNode":"bab9c5c5257cb2ae","fromSide":"bottom","toNode":"ce687c0218fbf7e7","toSide":"left"},
		{"id":"d189fb15f01904bf","fromNode":"bb3acbefb5138d9e","fromSide":"right","toNode":"82689f1bf8452e46","toSide":"left","label":"Use?"},
		{"id":"5941e4fb2b7b4d99","fromNode":"82689f1bf8452e46","fromSide":"bottom","toNode":"c4edcea482c21ffd","toSide":"top","label":"Cause Problem"},
		{"id":"b69f60117a8b1c38","fromNode":"bab9c5c5257cb2ae","fromSide":"right","toNode":"09f5694c5de6d427","toSide":"left"},
		{"id":"5c56a4bff7f9bbcd","fromNode":"334846dd2fb9f31a","fromSide":"top","toNode":"532225b24fc30400","toSide":"bottom"},
		{"id":"ff338377e2150c1f","fromNode":"0554543036236b0c","fromSide":"right","toNode":"53044a1aabfc1cad","toSide":"left","toEnd":"none"},
		{"id":"f6892266a1e4f303","fromNode":"109e9b54e827bb4c","fromSide":"bottom","toNode":"c131cf6c3d854499","toSide":"top","toEnd":"none"},
		{"id":"f5cb10db1585fdeb","fromNode":"c131cf6c3d854499","fromSide":"right","toNode":"2c50295c0321bcea","toSide":"left"},
		{"id":"2440c8857273170e","fromNode":"53044a1aabfc1cad","fromSide":"right","toNode":"532225b24fc30400","toSide":"left"},
		{"id":"5af13ba30720b593","fromNode":"2c50295c0321bcea","fromSide":"right","toNode":"5f13b1ee5a93a3fb","toSide":"left","label":"Step 1"},
		{"id":"6f09dc260268b6ba","fromNode":"532225b24fc30400","fromSide":"right","toNode":"51132313db89b266","toSide":"left"},
		{"id":"d30d3032d0523848","fromNode":"532225b24fc30400","fromSide":"right","toNode":"8b77a5f9e1d7f993","toSide":"left"},
		{"id":"f136c04cef8d109c","fromNode":"8b77a5f9e1d7f993","fromSide":"right","toNode":"940bfde65ea878bc","toSide":"left"},
		{"id":"aa3a4401f676c731","fromNode":"2c50295c0321bcea","fromSide":"right","toNode":"372204348461db3b","toSide":"left","label":"Step 2"},
		{"id":"593b1a205a16f8c4","fromNode":"372204348461db3b","fromSide":"right","toNode":"068a13e34f0f4e71","toSide":"left"},
		{"id":"dc7ca77201b33601","fromNode":"068a13e34f0f4e71","fromSide":"right","toNode":"c6da0baf5ee2e7df","toSide":"left","label":"Idea"},
		{"id":"094acf6d024fced7","fromNode":"068a13e34f0f4e71","fromSide":"right","toNode":"68663e6cc7fc1595","toSide":"left"},
		{"id":"c70ae1316258dc11","fromNode":"c6da0baf5ee2e7df","fromSide":"right","toNode":"a43d61cea31a2658","toSide":"left","label":"Means"},
		{"id":"6212b83f5b763cd8","fromNode":"68663e6cc7fc1595","fromSide":"right","toNode":"0861e61a83d98cc3","toSide":"left"},
		{"id":"cebbc59b8053f074","fromNode":"a43d61cea31a2658","fromSide":"right","toNode":"0861e61a83d98cc3","toSide":"top","label":"Which"},
		{"id":"2c370d040164021a","fromNode":"0861e61a83d98cc3","fromSide":"bottom","toNode":"f8b35a7d2c8e3c79","toSide":"top","label":"So We Use"},
		{"id":"53e19e05f66947a2","fromNode":"f8b35a7d2c8e3c79","fromSide":"right","toNode":"972c07fb3d09aedd","toSide":"left"},
		{"id":"0ab86b1c467d1b5d","fromNode":"972c07fb3d09aedd","fromSide":"right","toNode":"9170ba380be1996d","toSide":"left"},
		{"id":"ca267c68afc946d0","fromNode":"9170ba380be1996d","fromSide":"right","toNode":"892c5a26a2062433","toSide":"left","label":"Little Spice"},
		{"id":"db90b2c4e1c259b0","fromNode":"c2dbd2b46a277158","fromSide":"bottom","toNode":"c615d72d9e188331","toSide":"right","label":"Why only last vector?"},
		{"id":"c660c8548fc53ea9","fromNode":"c615d72d9e188331","fromSide":"left","toNode":"6874e44b17f68800","toSide":"right"},
		{"id":"380a2103356f7991","fromNode":"6874e44b17f68800","fromSide":"left","toNode":"76d11cda2cf9378d","toSide":"right"},
		{"id":"66b4b12747bd9c9c","fromNode":"892c5a26a2062433","fromSide":"right","toNode":"2118b76aceaa9883","toSide":"left"},
		{"id":"51b08a9d05915ac9","fromNode":"892c5a26a2062433","fromSide":"top","toNode":"5c6e4cc625757bb4","toSide":"left"}
	]
}